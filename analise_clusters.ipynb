{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEHEI8/WhwDN8FHVzG8j9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarolineAndradeR/Data-Science/blob/main/analise_clusters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conceitos**"
      ],
      "metadata": {
        "id": "Eoh_h3IDmKkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encontrar grupos de informação, produtos ou até mesmo pessoas com base em dados, pode ser chamada de análise de cluster ou análise de conglomerados.\n",
        "\n",
        "Definição - Técnica de ML não supervisionada que permite agrupar dados em grupos homogêneos em função do grau de similiaridade entre os indivíduos por meio de características selecionadas.\n",
        "\n",
        "Correlação - Coeficiente que mede a força e doreção do relacionamento linear entre duas variáveis.\n",
        "\n",
        "Similaridade - Medida de proximidade, ou seja, deve ser comparar pares de objetos e aplicar medidas de distâncas, essas métricas verifica o quanto um indivíduo é diferente do outro.\n",
        "\n",
        "Quando buscamos agrupar variáveis (colunas do banco de dados) utilizamos a correlação. Quando precisamos comparar indivíduos (as linhas do banco de dados) aplicamos métricas de similaridade, onde as medidas de distância serão importantes.\n",
        "\n",
        "**Etapas para realizar uma análise de cluster**\n",
        "\n",
        "1. Escolha das variáveis, identificação de outliers, padronização.\n",
        "\n",
        "A seleção das variáveis é uma decisão combinada entre as áreas de negócios e Analytics. Identificação de outliers é uma etapa importante para encontrar nos dados valores acima ou abaixo do considerado normal.\n",
        "A tarefa mais importante é a padronização das variáveis, em diversos momentos, as colunas possuem unidades de medidas diferentes e nesse caso, não podemos aplicar o algoritmo diretamente, precisamos ajustar esses dados.\n",
        "\n",
        "2. MEDIDA DE DISTÂNCIA (SIMILARIDADE).\n",
        "\n",
        "Aaplicar a medida de distância, a métrica mais utilizada em análise de cluster é a distância euclidiana. Essa métrica é uma generalização do teorema de Pitágoras.\n",
        "\n",
        "3. ESCOLHA DO ALGORITMO DE AGRUPAMENTO (HIERÁRQUICOS E NÃO HIERÁRQUICOS).\n",
        "\n",
        "Buscar uma forma de organizar cada indivíduo no seu respectivo grupo. Definição do método de agrupamento. Existe 2 gerais, hierárquicos e não hierárquicos e o método híbrido que é a combinação dos dois. Os algoritmos hierárquicos geram os grupos de forma iterativa, em cada etapa, é vista a distâncias entre os múltiplos indivíduos e as menores distâncias são agrupadas formando os clusters e no final, um coeficiente de aglomeração é obtido informando em cada iteração como os grupos foram ajustados.\n",
        "E no caso dos não hierárquicos, é preciso definir a quantidade de grupos no inicio e após isso, a cada iteração as distâncias são obtidas e os grupos são formados.\n",
        "\n",
        "4. ESCOLHA DA QUANTIDADE DE GRUPOS.\n",
        "\n",
        "Nos métodos hierárquicos quanto nos algoritmos não hierárquicos existe técnicas para obter o número ideal de clusters. Não tem um padrão sobre quais as melhores ou mais eficientes, porém adota-se os hierárquicos para auxiliar no processo de obter esse número ideal.\n",
        "\n",
        "5. INTERPRETAÇÃO DOS GRUPOS\n",
        "\n",
        "Interpretar os grupos propostos pela análise. Uma vez que os algoritmos de aglomeração são não supervisionados, não tem uma medida direta para avaliar se a solução apresentada foi assertiva ou não. Uma alinhamento com a equipe de negócios e analistas deve ser organizada. Traduzir os resultados é a criação de personas que representam as características gerais dos grupos, esses resultado pode combinar os grupos formados pelas variáveis intervalares e combinar com variáveis qualitativas."
      ],
      "metadata": {
        "id": "tspYTOFCmQtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prática**"
      ],
      "metadata": {
        "id": "9d4c6NUDvirr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8rQ_Lmzl_Rm"
      },
      "outputs": [],
      "source": [
        "# gerais\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# cluster\n",
        "import scipy.cluster.hierarchy as shc\n",
        "from sklearn.preprocessing import MinMaxScaler, scale\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# carregar dados\n",
        "dados = pd.read_csv('rfm_analysis.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dados rfm\n",
        "dados.head()"
      ],
      "metadata": {
        "id": "Cza2NpYuv4Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selecionar colunas\n",
        "cols = ['Recency', 'Frequency', 'Monetary_Value']\n",
        "dados_cluster = dados[cols]\n",
        "\n",
        "# min-max\n",
        "minmax_scaler = MinMaxScaler()\n",
        "dados_minmax = minmax_scaler.fit_transform(dados_cluster)\n",
        "dados_minmax.shape\n",
        "\n",
        "# normalizar\n",
        "dados_normalizados = scale(dados_cluster)\n",
        "dados_normalizados.shape"
      ],
      "metadata": {
        "id": "ZkBjWDd-v6sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# min-max dataframe\n",
        "dados_minmax = pd.DataFrame(dados_minmax, columns=dados_cluster.columns)\n",
        "dados_minmax['CustomerID'] = dados['CustomerID']\n",
        "dados_minmax.head()\n",
        "\n",
        "# scale dataframe\n",
        "dados_normalizados = pd.DataFrame(dados_normalizados, columns=dados_cluster.columns)\n",
        "dados_normalizados['CustomerID'] = dados['CustomerID']\n",
        "dados_normalizados.head()"
      ],
      "metadata": {
        "id": "-KtjDtWxv-Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# algoritmo hierarquico\n",
        "dados_cluster_hierarquico = dados_normalizados[cols].sample(300, random_state = 5461)\n",
        "cluster_hier = shc.linkage(dados_cluster_hierarquico, method='ward')\n",
        "# grafico\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.title(\"Dendograma\")\n",
        "dend = shc.dendrogram(cluster_hier)\n",
        "plt.axhline(y=10, color='r', linestyle='--')"
      ],
      "metadata": {
        "id": "C2e0Yg5bwABn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# algoritmo hierarquico\n",
        "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward', compute_distances=True)\n",
        "cluster.fit(dados_cluster_hierarquico)\n",
        "distancias_grupos = pd.DataFrame(cluster.distances_, columns = ['distancia'])\n",
        "distancias_grupos['iteracao'] = distancias_grupos.index\n",
        "distancias_grupos['qtd_grupos'] = (max(distancias_grupos['iteracao']) - distancias_grupos['iteracao'])+1\n",
        "\n",
        "# grafico\n",
        "n_cluster_test = 15\n",
        "avaliacao_clusters = distancias_grupos[distancias_grupos['qtd_grupos'] <= n_cluster_test][['distancia', 'qtd_grupos']]\n",
        "plt.plot(avaliacao_clusters['qtd_grupos'], avaliacao_clusters['distancia'], '-o')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cLTmRM01wCGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obter grupos\n",
        "dados_cluster_hierarquico['cluster'] = cluster.fit_predict(dados_cluster_hierarquico)\n",
        "\n",
        "# centroides\n",
        "centroides = dados_cluster_hierarquico.groupby('cluster')                      .agg(media_recencia = pd.NamedAgg('Recency', 'mean'),\n",
        "                          media_frequencia = pd.NamedAgg('Frequency', 'mean'),\n",
        "                          media_valor = pd.NamedAgg('Monetary_Value', 'mean'))\n",
        "centroides"
      ],
      "metadata": {
        "id": "CM03hIoGwEHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# treinamento\n",
        "cluster_kmeans = KMeans(n_clusters = 3, init = centroides.values, n_init=1, max_iter = 1000)\n",
        "cluster_kmeans.fit(dados_normalizados[cols])\n",
        "# associar os clusters aos dados\n",
        "dados['cluster'] = cluster_kmeans.predict(dados_normalizados[cols])\n",
        "dados.head()"
      ],
      "metadata": {
        "id": "WUWCe4I1wGCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# contagem\n",
        "dados.groupby('cluster').size().to_frame('n')"
      ],
      "metadata": {
        "id": "9aRlaAY-wH6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# centroides dos grupos\n",
        "centroides_final = dados.groupby('cluster')      .agg(media_recencia = pd.NamedAgg('Recency', 'mean'),\n",
        "          media_frequencia = pd.NamedAgg('Frequency', 'mean'),\n",
        "          media_valor = pd.NamedAgg('Monetary_Value', 'mean'))\n",
        "# medias gerais\n",
        "media_recencia = np.mean(centroides_final['media_recencia'])\n",
        "media_frequencia = np.mean(centroides_final['media_frequencia'])\n",
        "media_valor = np.mean(centroides_final['media_valor'])\n",
        "# regras de avaliacao\n",
        "centroides_ajustado = centroides_final.copy()\n",
        "centroides_ajustado['media_recencia'] = np.where(centroides_final['media_recencia'] > media_recencia, 'alto', 'baixo')\n",
        "centroides_ajustado['media_frequencia'] = np.where(centroides_final['media_frequencia'] > media_frequencia, 'alto', 'baixo')\n",
        "centroides_ajustado['media_valor'] = np.where(centroides_final['media_valor'] > media_valor, 'alto', 'baixo')\n",
        "# ver os resultados\n",
        "centroides_ajustado"
      ],
      "metadata": {
        "id": "7Gf7Lnj1wJx5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}